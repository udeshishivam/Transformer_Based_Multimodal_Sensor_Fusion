Using TensorFlow backend.
[INFO] loading images...
[INFO] shuffle images
[INFO] preprocessing images
[INFO] intensity changing
[INFO] making test and training images
[INFO] converting labels images
[INFO] done
WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.

C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.
  warnings.warn('`epsilon` argument is deprecated and '
WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\tensorflow_core\python\ops\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

Train on 7393 samples, validate on 1849 samples
Epoch 1/100
WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

2020-01-29 17:38:49.819435: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-01-29 17:38:49.830555: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING:tensorflow:From C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.

OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 0 thread 1
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 1 thread 0
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 2 thread 0
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 2 thread 1
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 3 thread 0
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 15160 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 6976 thread 1 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 10992 thread 2 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 8976 thread 3 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 6412 thread 4 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 1588 thread 5 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 12164 thread 6 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 3316 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 5436 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 10860 thread 9 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 3972 thread 10 bound to OS proc set 4
   4/7393 [..............................] - ETA: 28:52 - loss: 1.7932 - acc: 0.2500OMP: Info #250: KMP_AFFINITY: pid 1816 tid 3528 thread 11 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 11156 thread 12 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 564 thread 13 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 9636 thread 14 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 13352 thread 18 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 4076 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 8836 thread 16 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 4572 thread 17 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 13584 thread 19 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 11996 thread 20 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 2196 thread 21 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 13324 thread 22 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 13060 thread 23 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 12716 thread 24 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 7716 thread 25 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 12028 thread 26 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 10084 thread 27 bound to OS proc set 6
  12/7393 [..............................] - ETA: 10:15 - loss: 1.7894 - acc: 0.2500OMP: Info #250: KMP_AFFINITY: pid 1816 tid 1820 thread 29 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 1816 tid 12416 thread 30 bound to OS proc set 5
7393/7393 [==============================] - 7s 1ms/step - loss: 1.5656 - acc: 0.3469 - val_loss: 1.5131 - val_acc: 0.3229
Epoch 2/100
7393/7393 [==============================] - 6s 833us/step - loss: 1.5075 - acc: 0.3717 - val_loss: 1.4823 - val_acc: 0.4094
Epoch 3/100
7393/7393 [==============================] - 6s 833us/step - loss: 1.4846 - acc: 0.4002 - val_loss: 1.4385 - val_acc: 0.4554
Epoch 4/100
7393/7393 [==============================] - 6s 829us/step - loss: 1.4315 - acc: 0.4342 - val_loss: 1.3861 - val_acc: 0.4673
Epoch 5/100
7393/7393 [==============================] - 6s 854us/step - loss: 1.3934 - acc: 0.4401 - val_loss: 1.3448 - val_acc: 0.4889
Epoch 6/100
7393/7393 [==============================] - 6s 843us/step - loss: 1.3741 - acc: 0.4492 - val_loss: 1.4106 - val_acc: 0.4100
Epoch 7/100
7393/7393 [==============================] - 6s 810us/step - loss: 1.3634 - acc: 0.4427 - val_loss: 1.3019 - val_acc: 0.5068
Epoch 8/100
7393/7393 [==============================] - 6s 824us/step - loss: 1.3455 - acc: 0.4622 - val_loss: 1.2901 - val_acc: 0.5100
Epoch 9/100
7393/7393 [==============================] - 6s 833us/step - loss: 1.3416 - acc: 0.4560 - val_loss: 1.2842 - val_acc: 0.5122
Epoch 10/100
7393/7393 [==============================] - 6s 843us/step - loss: 1.3334 - acc: 0.4721 - val_loss: 1.2719 - val_acc: 0.5160
Epoch 11/100
7393/7393 [==============================] - 6s 854us/step - loss: 1.3228 - acc: 0.4830 - val_loss: 1.2724 - val_acc: 0.5403
Epoch 12/100
7393/7393 [==============================] - 6s 841us/step - loss: 1.3209 - acc: 0.4861 - val_loss: 1.2752 - val_acc: 0.5327
Epoch 13/100
7393/7393 [==============================] - 6s 843us/step - loss: 1.3103 - acc: 0.5016 - val_loss: 1.2619 - val_acc: 0.5316
Epoch 14/100
7393/7393 [==============================] - 6s 845us/step - loss: 1.3072 - acc: 0.5007 - val_loss: 1.2793 - val_acc: 0.5176
Epoch 15/100
7393/7393 [==============================] - 6s 841us/step - loss: 1.2992 - acc: 0.5049 - val_loss: 1.2545 - val_acc: 0.5381
Epoch 16/100
7393/7393 [==============================] - 6s 858us/step - loss: 1.2939 - acc: 0.5095 - val_loss: 1.2526 - val_acc: 0.5197
Epoch 17/100
7393/7393 [==============================] - 6s 869us/step - loss: 1.2948 - acc: 0.5095 - val_loss: 1.2552 - val_acc: 0.5452
Epoch 18/100
7393/7393 [==============================] - 6s 841us/step - loss: 1.2893 - acc: 0.5151 - val_loss: 1.2375 - val_acc: 0.5571
Epoch 19/100
7393/7393 [==============================] - 6s 860us/step - loss: 1.2815 - acc: 0.5145 - val_loss: 1.5405 - val_acc: 0.3396
Epoch 20/100
7393/7393 [==============================] - 6s 839us/step - loss: 1.2849 - acc: 0.5162 - val_loss: 1.2361 - val_acc: 0.5398
Epoch 21/100
7393/7393 [==============================] - 6s 877us/step - loss: 1.2744 - acc: 0.5175 - val_loss: 1.2366 - val_acc: 0.5398
Epoch 22/100
7393/7393 [==============================] - 6s 848us/step - loss: 1.2672 - acc: 0.5278 - val_loss: 1.2360 - val_acc: 0.5230
Epoch 23/100
7393/7393 [==============================] - 6s 867us/step - loss: 1.2634 - acc: 0.5298 - val_loss: 1.2059 - val_acc: 0.5684
Epoch 24/100
7393/7393 [==============================] - 6s 860us/step - loss: 1.2563 - acc: 0.5286 - val_loss: 1.2381 - val_acc: 0.5376
Epoch 25/100
7393/7393 [==============================] - 6s 862us/step - loss: 1.2529 - acc: 0.5306 - val_loss: 1.2087 - val_acc: 0.5603
Epoch 26/100
7393/7393 [==============================] - 6s 860us/step - loss: 1.2437 - acc: 0.5327 - val_loss: 1.1933 - val_acc: 0.5754
Epoch 27/100
7393/7393 [==============================] - 7s 881us/step - loss: 1.2396 - acc: 0.5325 - val_loss: 1.2005 - val_acc: 0.5630
Epoch 28/100
7393/7393 [==============================] - 6s 871us/step - loss: 1.2367 - acc: 0.5319 - val_loss: 1.1886 - val_acc: 0.5690
Epoch 29/100
7393/7393 [==============================] - 6s 865us/step - loss: 1.2350 - acc: 0.5325 - val_loss: 1.2309 - val_acc: 0.5349
Epoch 30/100
7393/7393 [==============================] - 7s 924us/step - loss: 1.2262 - acc: 0.5365 - val_loss: 1.1795 - val_acc: 0.5679
Epoch 31/100
7393/7393 [==============================] - 6s 875us/step - loss: 1.2259 - acc: 0.5339 - val_loss: 1.1716 - val_acc: 0.5560
Epoch 32/100
7393/7393 [==============================] - 7s 879us/step - loss: 1.2217 - acc: 0.5316 - val_loss: 1.1749 - val_acc: 0.5603
Epoch 33/100
7393/7393 [==============================] - 6s 867us/step - loss: 1.2083 - acc: 0.5405 - val_loss: 1.1983 - val_acc: 0.5441
Epoch 34/100
7393/7393 [==============================] - 7s 879us/step - loss: 1.2139 - acc: 0.5394 - val_loss: 1.1719 - val_acc: 0.5630
Epoch 35/100
7393/7393 [==============================] - 7s 884us/step - loss: 1.2068 - acc: 0.5386 - val_loss: 1.1597 - val_acc: 0.5668
Epoch 36/100
7393/7393 [==============================] - 6s 877us/step - loss: 1.2047 - acc: 0.5465 - val_loss: 1.1566 - val_acc: 0.5700
Epoch 37/100
7393/7393 [==============================] - 7s 881us/step - loss: 1.1975 - acc: 0.5492 - val_loss: 1.1659 - val_acc: 0.5619
Epoch 38/100
7393/7393 [==============================] - 7s 884us/step - loss: 1.1875 - acc: 0.5494 - val_loss: 1.1494 - val_acc: 0.5663
Epoch 39/100
7393/7393 [==============================] - 7s 903us/step - loss: 1.1828 - acc: 0.5571 - val_loss: 1.2901 - val_acc: 0.4565
Epoch 40/100
7393/7393 [==============================] - 7s 879us/step - loss: 1.2019 - acc: 0.5402 - val_loss: 1.1432 - val_acc: 0.5733
Epoch 41/100
7393/7393 [==============================] - 7s 892us/step - loss: 1.1816 - acc: 0.5505 - val_loss: 1.1389 - val_acc: 0.5765
Epoch 42/100
7393/7393 [==============================] - 7s 960us/step - loss: 1.1850 - acc: 0.5544 - val_loss: 1.1668 - val_acc: 0.5522
Epoch 43/100
7393/7393 [==============================] - 6s 875us/step - loss: 1.1773 - acc: 0.5538 - val_loss: 1.1617 - val_acc: 0.5592
Epoch 44/100
7393/7393 [==============================] - 7s 890us/step - loss: 1.1751 - acc: 0.5540 - val_loss: 1.1352 - val_acc: 0.5673
Epoch 45/100
7393/7393 [==============================] - 7s 894us/step - loss: 1.1711 - acc: 0.5554 - val_loss: 1.1203 - val_acc: 0.5733
Epoch 46/100
7393/7393 [==============================] - 7s 898us/step - loss: 1.1718 - acc: 0.5603 - val_loss: 1.1420 - val_acc: 0.5560
Epoch 47/100
7393/7393 [==============================] - 7s 886us/step - loss: 1.1585 - acc: 0.5688 - val_loss: 1.1136 - val_acc: 0.5873
Epoch 48/100
7393/7393 [==============================] - 7s 890us/step - loss: 1.1636 - acc: 0.5670 - val_loss: 1.1221 - val_acc: 0.5803
Epoch 49/100
7393/7393 [==============================] - 7s 884us/step - loss: 1.1569 - acc: 0.5638 - val_loss: 1.1263 - val_acc: 0.5765
Epoch 50/100
7393/7393 [==============================] - 7s 945us/step - loss: 1.1564 - acc: 0.5718 - val_loss: 1.1669 - val_acc: 0.5587
Epoch 51/100
7393/7393 [==============================] - 7s 894us/step - loss: 1.1485 - acc: 0.5764 - val_loss: 1.1011 - val_acc: 0.5771
Epoch 52/100
7393/7393 [==============================] - 7s 913us/step - loss: 1.1493 - acc: 0.5731 - val_loss: 1.0994 - val_acc: 0.5782
Epoch 53/100
7393/7393 [==============================] - 7s 945us/step - loss: 1.1449 - acc: 0.5728 - val_loss: 1.1447 - val_acc: 0.5522
Epoch 54/100
7393/7393 [==============================] - 7s 886us/step - loss: 1.1339 - acc: 0.5735 - val_loss: 1.1111 - val_acc: 0.5949
Epoch 55/100
7393/7393 [==============================] - 7s 892us/step - loss: 1.1344 - acc: 0.5766 - val_loss: 1.1139 - val_acc: 0.5657
Epoch 56/100
7393/7393 [==============================] - 7s 892us/step - loss: 1.1190 - acc: 0.5919 - val_loss: 1.0950 - val_acc: 0.5922
Epoch 57/100
7393/7393 [==============================] - 7s 943us/step - loss: 1.1227 - acc: 0.5873 - val_loss: 1.0938 - val_acc: 0.6101
Epoch 58/100
7393/7393 [==============================] - 7s 917us/step - loss: 1.1195 - acc: 0.5873 - val_loss: 1.0858 - val_acc: 0.6036
Epoch 59/100
7393/7393 [==============================] - 7s 928us/step - loss: 1.1148 - acc: 0.5857 - val_loss: 1.0901 - val_acc: 0.6014
Epoch 60/100
7393/7393 [==============================] - 7s 898us/step - loss: 1.1204 - acc: 0.5862 - val_loss: 1.0881 - val_acc: 0.6025
Epoch 61/100
7393/7393 [==============================] - 7s 898us/step - loss: 1.1137 - acc: 0.5939 - val_loss: 1.0940 - val_acc: 0.5944
Epoch 62/100
7393/7393 [==============================] - 7s 911us/step - loss: 1.1085 - acc: 0.5910 - val_loss: 1.1013 - val_acc: 0.5938
Epoch 63/100
7393/7393 [==============================] - 7s 900us/step - loss: 1.1038 - acc: 0.5930 - val_loss: 1.1023 - val_acc: 0.5776
Epoch 64/100
7393/7393 [==============================] - 7s 909us/step - loss: 1.0921 - acc: 0.6011 - val_loss: 1.0828 - val_acc: 0.6068
Epoch 65/100
7393/7393 [==============================] - 7s 928us/step - loss: 1.0992 - acc: 0.5891 - val_loss: 1.1724 - val_acc: 0.5484
Epoch 66/100
7393/7393 [==============================] - 7s 913us/step - loss: 1.0968 - acc: 0.5960 - val_loss: 1.0865 - val_acc: 0.6095
Epoch 67/100
7393/7393 [==============================] - 7s 924us/step - loss: 1.0894 - acc: 0.6046 - val_loss: 1.0750 - val_acc: 0.6155
Epoch 68/100
7393/7393 [==============================] - 7s 934us/step - loss: 1.0862 - acc: 0.5995 - val_loss: 1.3355 - val_acc: 0.5057
Epoch 69/100
7393/7393 [==============================] - 7s 909us/step - loss: 1.0749 - acc: 0.6026 - val_loss: 1.1681 - val_acc: 0.5381
Epoch 70/100
7393/7393 [==============================] - 7s 919us/step - loss: 1.0726 - acc: 0.6110 - val_loss: 1.0630 - val_acc: 0.6101
Epoch 71/100
7393/7393 [==============================] - 7s 930us/step - loss: 1.0694 - acc: 0.6103 - val_loss: 1.1342 - val_acc: 0.5890
Epoch 72/100
7393/7393 [==============================] - 7s 915us/step - loss: 1.0737 - acc: 0.6099 - val_loss: 1.1370 - val_acc: 0.5489
Epoch 73/100
7393/7393 [==============================] - 7s 915us/step - loss: 1.0505 - acc: 0.6248 - val_loss: 1.0856 - val_acc: 0.5982
Epoch 74/100
7393/7393 [==============================] - 7s 926us/step - loss: 1.0557 - acc: 0.6165 - val_loss: 1.1306 - val_acc: 0.5949
Epoch 75/100
7393/7393 [==============================] - 7s 917us/step - loss: 1.0546 - acc: 0.6180 - val_loss: 1.0611 - val_acc: 0.6203
Epoch 76/100
7393/7393 [==============================] - 7s 941us/step - loss: 1.0499 - acc: 0.6207 - val_loss: 1.0618 - val_acc: 0.6122
Epoch 77/100
7393/7393 [==============================] - 7s 919us/step - loss: 1.0374 - acc: 0.6298 - val_loss: 1.0617 - val_acc: 0.6122
Epoch 78/100
7393/7393 [==============================] - 7s 928us/step - loss: 1.0378 - acc: 0.6284 - val_loss: 1.0658 - val_acc: 0.6193
Epoch 79/100
7393/7393 [==============================] - 7s 926us/step - loss: 1.0405 - acc: 0.6267 - val_loss: 1.0691 - val_acc: 0.6106
Epoch 80/100
7393/7393 [==============================] - 7s 936us/step - loss: 1.0277 - acc: 0.6292 - val_loss: 1.3841 - val_acc: 0.5003
Epoch 81/100
7393/7393 [==============================] - 7s 930us/step - loss: 1.0286 - acc: 0.6311 - val_loss: 1.0815 - val_acc: 0.5982
Epoch 82/100
7393/7393 [==============================] - 7s 941us/step - loss: 1.0160 - acc: 0.6347 - val_loss: 1.0879 - val_acc: 0.6014
Epoch 83/100
7393/7393 [==============================] - 7s 945us/step - loss: 1.0139 - acc: 0.6361 - val_loss: 1.0822 - val_acc: 0.6025
Epoch 84/100
7393/7393 [==============================] - 7s 945us/step - loss: 1.0038 - acc: 0.6398 - val_loss: 1.0893 - val_acc: 0.6036
Epoch 85/100
7393/7393 [==============================] - 7s 996us/step - loss: 0.9980 - acc: 0.6459 - val_loss: 1.0836 - val_acc: 0.5933
Epoch 86/100
7393/7393 [==============================] - 7s 998us/step - loss: 1.0134 - acc: 0.6348 - val_loss: 1.0639 - val_acc: 0.6165
Epoch 87/100
7393/7393 [==============================] - 7s 945us/step - loss: 0.9894 - acc: 0.6443 - val_loss: 1.0671 - val_acc: 0.6257
Epoch 88/100
7393/7393 [==============================] - 8s 1ms/step - loss: 0.9798 - acc: 0.6463 - val_loss: 1.0702 - val_acc: 0.6160
Epoch 89/100
7393/7393 [==============================] - 7s 947us/step - loss: 0.9779 - acc: 0.6464 - val_loss: 1.0902 - val_acc: 0.5906
Epoch 90/100
7393/7393 [==============================] - 7s 945us/step - loss: 0.9939 - acc: 0.6462 - val_loss: 1.0568 - val_acc: 0.6155
Epoch 91/100
7393/7393 [==============================] - 7s 964us/step - loss: 0.9730 - acc: 0.6491 - val_loss: 1.0582 - val_acc: 0.6214
Epoch 92/100
7393/7393 [==============================] - 7s 955us/step - loss: 0.9692 - acc: 0.6539 - val_loss: 1.0695 - val_acc: 0.6182
Epoch 93/100
7393/7393 [==============================] - 7s 960us/step - loss: 0.9728 - acc: 0.6455 - val_loss: 1.0881 - val_acc: 0.6117
Epoch 94/100
7393/7393 [==============================] - 7s 960us/step - loss: 0.9650 - acc: 0.6572 - val_loss: 1.0981 - val_acc: 0.6111
Epoch 95/100
7393/7393 [==============================] - 7s 960us/step - loss: 0.9503 - acc: 0.6613 - val_loss: 1.0872 - val_acc: 0.6090
Epoch 96/100
7393/7393 [==============================] - 7s 958us/step - loss: 0.9500 - acc: 0.6586 - val_loss: 1.0925 - val_acc: 0.6079
Epoch 97/100
7393/7393 [==============================] - 7s 964us/step - loss: 0.9380 - acc: 0.6693 - val_loss: 1.0608 - val_acc: 0.6144
Epoch 98/100
7393/7393 [==============================] - 7s 968us/step - loss: 0.9349 - acc: 0.6624 - val_loss: 1.0548 - val_acc: 0.6149
Epoch 99/100
7393/7393 [==============================] - 7s 985us/step - loss: 0.9275 - acc: 0.6648 - val_loss: 1.0722 - val_acc: 0.6263
Epoch 100/100
7393/7393 [==============================] - 7s 966us/step - loss: 0.9455 - acc: 0.6604 - val_loss: 1.0649 - val_acc: 0.6138
[INFO] evaluating network...
C:\Users\dima_r1ze5pa\Anaconda3\lib\site-packages\sklearn\metrics\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

      cloudy       0.54      0.69      0.60       566
       foggy       0.00      0.00      0.00        80
        rain       0.00      0.00      0.00       115
        snow       0.76      0.45      0.56       119
       sunny       0.80      0.80      0.80       597
     z-other       0.47      0.57      0.52       372

    accuracy                           0.61      1849
   macro avg       0.43      0.42      0.41      1849
weighted avg       0.57      0.61      0.58      1849